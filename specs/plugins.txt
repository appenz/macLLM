# macLLM Plugin Architecture Specification


## Base Plugin Class
```python
class MacLLMPlugin:
    # Required hooks
    def get_prefixes(self) -> list[str]:  # e.g. ["@http://", "@https://", "@~"]
        pass

    def expand(self, tag: str, request: UserRequest) -> None:
        pass

    # Optional config-time hooks (processed while reading shortcut files)
    def get_config_prefixes(self) -> list[str]:
        return []

    def on_config_tag(self, tag: str, value: str) -> None:
        pass

    # Optional dynamic-autocomplete hooks (for UI suggestions)
    def supports_autocomplete(self) -> bool:
        return False

    def autocomplete(self, fragment: str, max_results: int = 10) -> list[str]:
        return []

    def display_string(self, suggestion: str) -> str:
        return suggestion
```

## Plugin Examples
- **URLPlugin**: handles "@http://", "@https://" → fetches web content, adds to context
- **FilePlugin**: config tag "@IndexFiles" indexes .txt/.md directories; typing "@" + ≥3 chars shows matching files, selecting one inserts its contents into context
- **ClipboardPlugin**: handles "@clipboard" → gets clipboard content, adds to context
- **ImagePlugin**: handles "@selection", "@window" → captures screenshots, sets needs_image=True

## Model Architecture

### Base Model Connector
```python
class ModelConnector:
    def __init__(self, model: str, temperature: float = 0.0):
        self.model = model  # Required parameter - no default
        self.temperature = temperature
        self.context_limit = 10000
    
    def generate(self, text: str) -> str:
        pass
    
    def generate_with_image(self, text: str, image_path: str) -> str:
        pass
```

### Model Connectors
- **OpenAIConnector**: implements OpenAI API for GPT models
- **Future connectors**: Anthropic, local models, etc.

## Integration
- Main MacLLM class maintains list of registered plugins
- Main MacLLM class uses ModelConnector for LLM interactions
- handle_instructions() creates UserRequest object, passes to plugins
- Plugins modify the request object directly (no return values)
- Each plugin is self-contained and can be tested independently
- Easy to add new expansion types without modifying core logic

## Benefits
- No more tuple returns - cleaner interface
- Centralized state management in UserRequest
- Plugins can modify multiple aspects of the request
- Model abstraction allows easy switching between LLM providers
- More object-oriented and maintainable
