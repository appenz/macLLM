MacLLM is a tool that helps a user to effectively use LLMs for working on macOS.

A user enters a request (e.g. "What is 1+1?") and MacLLM replies with a result (e.g. "2").
A collection of requests/responses are called a Conversation.
A user can provide context, e.g. a file or data in the clipboard. Context is for the entire conversation.
The collection of all Conversations is called the ChatHistory
A Request is an ephemeral object that contains all the data that needs to be sent to the LLM, including context

Code Structure (source code file in paranthesis):
- MacLLM is the base class that implements the tool (macllm.py)
- MacLLMUI is the Cocoa UI for MacLLM (ui.py)
- Core building blocks are in the core/ subdirectory
- Plugins that add additional @ tags (e.g. @clipboard, file completion) are in the tags directory
- Connectors to LLMs and other models are in the models/ directory
- The ChatHistory, Conversations and Requests are stored in (chat_history.txt)
